# Proyectos de Machine Learning en Python

Este repositorio contiene cuatro proyectos de aprendizaje autom√°tico desarrollados en Jupyter Notebooks. Cada notebook aborda una tarea diferente y demuestra la aplicaci√≥n de diversos algoritmos y t√©cnicas, desde los fundamentos hasta flujos de trabajo m√°s avanzados, cabe mencionar que se realiz√≥ otro proyecto relacionado con las anomal√≠as sin embargo este se realiz√≥ en clase y por lo tanto no dispongo de ese material.

---

## üìÇ Contenido del Repositorio

### 1. `clasificacion.ipynb` - Comparativa de Algoritmos de Clasificaci√≥n
* **Tarea**: Clasificaci√≥n Supervisada.
* **Objetivo**: Comparar el rendimiento de cuatro algoritmos de clasificaci√≥n para predecir la aceptabilidad de un autom√≥vil.
* **Dataset**: Car Evaluation de UCI.
* **Conceptos**: Preprocesamiento de datos categ√≥ricos, entrenamiento de modelos y evaluaci√≥n basada en la m√©trica de exactitud (accuracy).
* **Algoritmos**: Perceptr√≥n, Regresi√≥n Log√≠stica, K-Vecinos m√°s Cercanos (KNN) y XGBoost.

### 2. `agrupamientos.ipynb` - Comparativa de Algoritmos de Clustering
* **Tarea**: Aprendizaje No Supervisado (Clustering).
* **Objetivo**: Identificar el n√∫mero √≥ptimo de grupos en el dataset Iris y comparar la calidad de los cl√∫steres resultantes de tres algoritmos diferentes.
* **Dataset**: Iris de Scikit-learn.
* **Conceptos**: Normalizaci√≥n de datos, M√©todo del Codo, Dendrogramas, Criterios AIC/BIC y evaluaci√≥n con el Coeficiente de Silueta.
* **Algoritmos**: K-Means, Clustering Aglomerativo y Modelos de Mezcla Gaussiana (GMM).

### 3. `pipelines.ipynb` - Flujos de Trabajo con Pipelines y GridSearchCV
* **Tarea**: Clasificaci√≥n Binaria y Evaluaci√≥n Robusta de Modelos.
* **Objetivo**: Construir un flujo de trabajo sistem√°tico para preprocesar, entrenar, optimizar y evaluar modelos de clasificaci√≥n para el diagn√≥stico de c√°ncer de mama.
* **Dataset**: Wisconsin Breast Cancer de UCI.
* **Conceptos**: `Pipelines` para encapsular flujos de trabajo, `GridSearchCV` para la b√∫squeda de hiperpar√°metros y **Validaci√≥n Cruzada Anidada** para una evaluaci√≥n imparcial del rendimiento.
* **Algoritmos**: Regresi√≥n Log√≠stica, M√°quinas de Vectores de Soporte (SVC) y XGBoost.

### 4. `regresi√≥n.ipynb` - Comparativa de Modelos de Regresi√≥n
El objetivo principal es aplicar un flujo de trabajo de machine learning para un problema de regresi√≥n. El proceso incluye:
1.  Carga y preparaci√≥n del dataset **California Housing**.
2.  Selecci√≥n de un subconjunto de caracter√≠sticas para el modelo.
3.  Divisi√≥n de los datos en conjuntos de entrenamiento y prueba.
4.  Entrenamiento y evaluaci√≥n de tres modelos distintos.
5.  Comparaci√≥n de su rendimiento utilizando m√©tricas est√°ndar.

## ‚ú® Modelos y M√©tricas

### Modelos Evaluados
Se implementan y comparan los siguientes algoritmos de regresi√≥n:
* **Regresi√≥n Lineal**: Como modelo base.
* **K-Vecinos m√°s Cercanos (KNN)**: Un enfoque no param√©trico.
* **XGBoost**: Un modelo avanzado de ensamblaje (ensemble).

### M√©tricas de Evaluaci√≥n
El rendimiento de cada modelo se mide con:
* **Coeficiente de Determinaci√≥n (R¬≤)**: Para medir la proporci√≥n de la varianza explicada por el modelo.
* **Ra√≠z del Error Cuadr√°tico Medio (RMSE)**: Para medir la magnitud del error de predicci√≥n.

## ‚ö†Ô∏è Nota Importante sobre la Calificaci√≥n Autom√°tica

Este notebook de `regresi√≥n.ipynb` incluye celdas con una funci√≥n de calificaci√≥n autom√°tica (`quiz.eval_numeric`) que pueden mostrar un `AssertionError`. **Estos errores deben ser ignorados**. Seg√∫n las indicaciones del instructor, los valores esperados por el calificador autom√°tico son incorrectos, mientras que los resultados calculados por el c√≥digo del notebook son los correctos.

---

## üîß Requisitos

Para ejecutar estos notebooks, necesitar√°s tener las siguientes librer√≠as de Python instaladas:

* `numpy`
* `pandas`
* `matplotlib`
* `scikit-learn`
* `xgboost`
* `yellowbrick` (para el notebook de agrupamientos)

Puedes instalarlas usando pip:
```bash
pip install numpy pandas matplotlib scikit-learn xgboost yellowbrick
```

## üöÄ C√≥mo Ejecutar
### 1.Clona o descarga este repositorio.
### 2. Abre una terminal y navega al directorio del proyecto.
### 3.Inicia Jupyter Notebook o Jupyter Lab:
`jupyter notebook`
### 4.Desde la interfaz de Jupyter en tu navegador, abre el notebook que desees explorar y ejecuta las celdas.
